{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd16b4e3",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f10a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af30684",
   "metadata": {},
   "source": [
    "### Build data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "236a640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path:str) -> List[float]: \n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))): \n",
    "        ret, frame = cap.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "        frames.append(frame[190:236,80:220,:])\n",
    "    cap.release()\n",
    "    \n",
    "    mean = tf.math.reduce_mean(frames)\n",
    "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
    "    return tf.cast((frames - mean), tf.float32) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef0a2a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary is: ['', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', \"'\", '?', '!', '1', '2', '3', '4', '5', '6', '7', '8', '9', ' '] (size =40)\n"
     ]
    }
   ],
   "source": [
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The vocabulary is: {char_to_num.get_vocabulary()} \"\n",
    "    f\"(size ={char_to_num.vocabulary_size()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ce00f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_alignments(path:str) -> List[str]: \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e85793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str): \n",
    "    path = bytes.decode(path.numpy())\n",
    "    #file_name = path.split('/')[-1].split('.')[0]\n",
    "    # File name splitting for windows\n",
    "    file_name = path.split('\\\\')[-1].split('.')[0]\n",
    "    video_path = os.path.join('data','s1',f'{file_name}.mpg')\n",
    "    alignment_path = os.path.join('data','alignments','s1',f'{file_name}.align')\n",
    "    frames = load_video(video_path) \n",
    "    alignments = load_alignments(alignment_path)\n",
    "    \n",
    "    return frames, alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0639c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mappable_function(path:str) ->List[str]:\n",
    "    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9621d62",
   "metadata": {},
   "source": [
    "### Prepare testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d3fa48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.data.Dataset.list_files('./data/s1/*.mpg')\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(mappable_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE) \n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af833831",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a93faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Conv3D, LSTM, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, SpatialDropout3D, BatchNormalization, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d0bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv3D(128, 3, input_shape=(75,46,140,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(256, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(75, 3, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, kernel_initializer='Orthogonal', return_sequences=True)))\n",
    "model.add(Dropout(.5))\n",
    "\n",
    "model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68c86a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 75, 46, 140, 128)  3584      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 75, 46, 140, 128)  0         \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 75, 23, 70, 128)  0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 75, 23, 70, 256)   884992    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 75, 23, 70, 256)   0         \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 75, 11, 35, 256)  0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 75, 11, 35, 75)    518475    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 75, 11, 35, 75)    0         \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 75, 5, 17, 75)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 75, 6375)         0         \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 75, 256)          6660096   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 75, 256)           0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 75, 256)          394240    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 75, 256)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 75, 41)            10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,471,924\n",
      "Trainable params: 8,471,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c24834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x13e87472050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('models/checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee351d2",
   "metadata": {},
   "source": [
    "### Build evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cad6c287",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "203e438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(actual_texts, predicted_texts):\n",
    "    # Flatten the lists of strings to lists of characters for character-level metrics\n",
    "    actual_chars = [char for text in actual_texts for char in list(text)]\n",
    "    predicted_chars = [char for text in predicted_texts for char in list(text)]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(actual_chars, predicted_chars)\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(actual_chars, predicted_chars, average='weighted')\n",
    "    recall = recall_score(actual_chars, predicted_chars, average='weighted')\n",
    "    f1 = f1_score(actual_chars, predicted_chars, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6150f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(actual_texts, predicted_texts):\n",
    "    for i in range(len(actual_texts)):\n",
    "        len_diff = len(actual_texts[i]) - len(predicted_texts[i])\n",
    "        if len_diff < 0:\n",
    "            actual_texts[i] += \" \"*abs(len_diff)\n",
    "        elif len_diff > 0:\n",
    "            predicted_texts[i] += \" \"*abs(len_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a38247",
   "metadata": {},
   "source": [
    "### Run evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba82c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9038759",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_texts = list()\n",
    "predicted_texts = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b32d0304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "iteration: 2\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 3\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 4\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 5\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 6\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 7\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 8\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 9\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 10\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 11\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 12\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 13\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 14\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 15\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 16\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 17\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 18\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 19\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 20\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 21\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 22\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 23\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 24\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 25\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 26\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 27\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 28\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 29\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 30\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 31\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 32\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 33\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 34\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 35\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 36\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 37\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 38\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 39\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 40\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 41\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 42\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 43\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 44\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 45\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 46\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 47\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 48\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 49\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "iteration: 50\n",
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test)):\n",
    "    print(\"iteration:\", i+1)\n",
    "    \n",
    "    # move to next set\n",
    "    sample = test_data.next()\n",
    "    \n",
    "    # get real text\n",
    "    yhat = model.predict(sample[0])\n",
    "    text_real = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in sample[1]]\n",
    "    text_real = [text_real[0].numpy().decode(), text_real[1].numpy().decode()]\n",
    "    actual_texts.extend(text_real)\n",
    "    \n",
    "    # get predicted text\n",
    "    decoded = tf.keras.backend.ctc_decode(yhat, input_length=[75,75], greedy=True)[0][0].numpy()\n",
    "    text_pred = [tf.strings.reduce_join([num_to_char(word) for word in sentence]) for sentence in decoded]\n",
    "    text_pred = [text_pred[0].numpy().decode(), text_pred[1].numpy().decode()]\n",
    "    predicted_texts.extend(text_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd0eb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add whitespace padding for unequal real-predicted pairs\n",
    "add_padding(actual_texts, predicted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff3dd744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9791415964701163\n",
      "Precision: 0.9792040812714483\n",
      "Recall: 0.9791415964701163\n",
      "F1 Score: 0.9791374960470012\n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1 = evaluate_performance(actual_texts, predicted_texts)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
